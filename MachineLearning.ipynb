{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCb1TiWi9pu+rOSNXZzWtG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RakeshBB08/MachineLearning/blob/master/MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# **DATA PREPROCESSING TOOLS:**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P7pvfrMXt690"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Importing the libraries\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Es9LYe7HvRF9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhEIyl7jtbE1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# allows us work with array data\n",
        "import matplotlib.pyplot as plt\n",
        "#  to plot the charts \n",
        "import pandas as pd\n",
        "# work with dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dataset\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YvvAu8Q3VRuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "# iloc used for locating the indexes [rows_start:rows_end,columns_start:columns_end]\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "2XDdGwfFVREg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaR6oo9NXkGl",
        "outputId": "179cd9af-47f2-4885-a800-15ec7b7ff9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID1jPjZxXmvB",
        "outputId": "571ed683-de47-4cf5-a53b-df0ecbb8717c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking care of missing data\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BtTNu21lUCZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import mean\n",
        "# 1) ignore the sample dataset\n",
        "# 2) replacing the missing data by the avg of all the values of the column\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean' ) # select the imputer method first \n",
        "imputer.fit(X[:,1:3]) # excludes final vlaue in range, after we model for the required columns\n",
        "X[:,1:3] = imputer.transform(X[:,1:3])\n",
        "X"
      ],
      "metadata": {
        "id": "m7N3guSmvWnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dc2fc2-7d2e-45e7-fbc6-9ce97219cde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, 63777.77777777778],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', 38.77777777777778, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoding categorical data**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6Wa_EdjxUID3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the independent variable\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UC1YRaL6UbgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding:\n",
        "# One-hot encoding in machine learning is the conversion of categorical information into a format that may be fed into machine learning algorithms to improve prediction accuracy\n",
        "# Used because to not to obtain any correlation while calculation for this column\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers= [('encoder',OneHotEncoder(),[0])],remainder='passthrough') # OneHotEncoder is class function call observe\n",
        "X = np.array(ct.fit_transform(X)) # fit_transform dosent return numpy arrary so we need to specify explicitly\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cIDn068UapX",
        "outputId": "5a2e193c-6b2c-4f8e-cfcc-c301da4102ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
              "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
              "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
              "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
              "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding the Dependent variable\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TrtJZoFMUjJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder \n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5l06E0GUijo",
        "outputId": "1ff3fa74-b319-425b-e863-018ce6f52763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5RDE6I9ZUrh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# creates a 4 separate set,Xtrain,Xtest,Ytrain,Ytest\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0) #random stae denotes the seeding of the splits\n"
      ],
      "metadata": {
        "id": "jXMpxBH7Uzbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6xuNcR6Um7g",
        "outputId": "fdbcef00-7717-4077-96d3-253ba072caa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
              "       [1.0, 0.0, 0.0, 37.0, 67000.0],\n",
              "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
              "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
              "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
              "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
              "       [1.0, 0.0, 0.0, 44.0, 72000.0],\n",
              "       [1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiP4_3gfUmqE",
        "outputId": "03efbfe9-ac33-4802-d1bf-c15f5045cbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPjJU3xrUxww",
        "outputId": "074cdb71-8fc3-4892-bee8-e82666760180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XER1Fx1DUz8Q",
        "outputId": "8bf826b4-5f50-4963-f358-87d8b58d9de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hq7fI__WU0V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to apply feature scaling after splitting the data set \n",
        "# feature scaling uses mean and other properties while tesing the model it should not be used in the training \n",
        "# if we use feature scaling before it may cause info leakage\n",
        "# standardisation values b/w -3 to 3 whereas in normalisation values b/w -1 and 1\n",
        "# std works all the time, but norm works better when there is normal distribution\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train[:,3:] = StandardScaler().fit_transform(X_train[:,3:])\n",
        "X_test[:,3:] = StandardScaler().fit_transform(X_test[:,3:])"
      ],
      "metadata": {
        "id": "WJ5BFAhDU4GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpNh7BfhYqhf",
        "outputId": "7400b5fb-46c7-4d84-a57a-4abd54dd0b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 0.2630675731713538, 0.1238147854838185],\n",
              "       [1.0, 0.0, 0.0, -0.25350147960148617, 0.4617563176278856],\n",
              "       [0.0, 0.0, 1.0, -1.9753983221776195, -1.5309334063940294],\n",
              "       [0.0, 0.0, 1.0, 0.05261351463427101, -1.1114197802841526],\n",
              "       [1.0, 0.0, 0.0, 1.6405850472322605, 1.7202971959575162],\n",
              "       [0.0, 0.0, 1.0, -0.08131179534387283, -0.16751412153692966],\n",
              "       [1.0, 0.0, 0.0, 0.9518263102018072, 0.9861483502652316],\n",
              "       [1.0, 0.0, 0.0, -0.5978808481167128, -0.48214934111933727]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSMCAia1YqDX",
        "outputId": "1a531896-2dfc-4b66-f008-5173fb68953d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
              "       [0.0, 1.0, 0.0, 50.0, 83000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Linear Regression**\n",
        "1. Ordinary Least Squares"
      ],
      "metadata": {
        "id": "ivYxvMOB-MiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y = b0 + b1*x\n",
        "in ols the sqaure of distance between the actual and the predicted is minimum"
      ],
      "metadata": {
        "id": "GWq7yuu3Bzu-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdZplM2pCSo6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}